# 07_1.indexing_with_metadata.ipynb


---

## 셀 1: 필요한 패키지 설치

이 첫 번째 셀에서는 이번 실습에 필요한 파이썬 라이브러리들을 설치합니다. `%pip install ...` 명령을 통해 **python-dotenv**, **pandas**, **pinecone**, **langchain**, **langchain-openai**, **langchain-pinecone** 등을 설치하거나 이미 설치되어 있는지 확인합니다. 이러한 패키지들은 환경 변수를 관리하고( dotenv ), 데이터 처리(pandas), 벡터 데이터베이스(Pinecone) 및 LLM 연동(LangChain 및 관련 모듈)에 사용됩니다. 이 셀을 실행하면 필요한 패키지들이 모두 준비되었는지 출력으로 알려줍니다.

```python
%pip install python-dotenv pandas pinecone langchain langchain-openai langchain-pinecone
```

**출력 설명:** 각 패키지에 대해 "Requirement already satisfied"라는 메시지가 보입니다. 이는 해당 패키지들이 이미 현재 환경에 설치되어 있어서 추가 설치가 필요 없음을 나타냅니다. 즉, 환경에 필요한 모든 라이브러리가 이미 갖춰져 있다는 확인 결과입니다.

```plaintext
Requirement already satisfied: python-dotenv in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (1.1.0)
Requirement already satisfied: pandas in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (2.3.0)
Requirement already satisfied: pinecone in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (7.0.2)
Requirement already satisfied: langchain in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (0.3.25)
Requirement already satisfied: langchain-openai in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (0.3.21)
Requirement already satisfied: langchain-pinecone in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (0.2.8)
Requirement already satisfied: numpy>=1.26.0 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pandas) (2.2.6)
Requirement already satisfied: python-dateutil>=2.8.2 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pandas) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pandas) (2025.2)
Requirement already satisfied: certifi>=2019.11.17 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pinecone) (2025.4.26)
Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pinecone) (1.6.1)
Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pinecone) (0.0.7)
Requirement already satisfied: typing-extensions>=3.7.4 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pinecone) (4.14.0)
Requirement already satisfied: urllib3>=1.26.5 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pinecone) (2.4.0)
Requirement already satisfied: packaging<25.0,>=24.2 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)
Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\users\ssampooh\rag-retrieval\.conda\lib\site-packages (from pinecone) (2.32.3)
```

---

## 셀 2: 환경 변수 로딩

이 셀에서는 Pinecone 및 OpenAI API 키와 설정 값들을 **환경 변수**에서 불러옵니다. `dotenv` 패키지의 `load_dotenv()` 함수를 호출하여 `.env` 파일에 저장된 환경 변수들을 현재 실행 환경으로 가져옵니다. 그런 다음 `os.getenv()`를 이용해 필요한 키 값을 읽어서 변수에 저장합니다. 예를 들어 `OPENAI_API_KEY`와 `PINECONE_API_KEY` 등이 해당 환경 변수에서 불러온 값입니다. 마지막에 `print("환경 변수 로딩 완료")`로 모든 환경 변수 로드가 완료되었음을 알려줍니다. 이 과정을 통해 API 키나 인덱스 이름처럼 민감한 정보도 코드에 직접 노출하지 않고 사용할 수 있습니다.

```python
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_LLM_MODEL = os.getenv("OPENAI_LM_MODEL")
OPENAI_EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_REGION = os.getenv("PINECONE_INDEX_REGION")
PINECONE_INDEX_CLOUD = os.getenv("PINECONE_INDEX_CLOUD")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")
PINECONE_INDEX_METRIC = os.getenv("PINECONE_INDEX_METRIC")
PINECONE_INDEX_DIMENSION = int(os.getenv("PINECONE_INDEX_DIMENSION"))

print("환경 변수 로딩 완료")
```

**출력 설명:** `"환경 변수 로딩 완료"`라는 메시지가 출력되었습니다. 이는 `.env` 파일로부터 API 키나 인덱스 이름 등의 환경 변수들을 모두 성공적으로 불러왔음을 의미합니다. 이 출력으로 환경 설정 단계가 제대로 마무리되었음을 확인할 수 있습니다.

```plaintext
환경 변수 로딩 완료
```

---

## 셀 3: 데이터 불러오기 및 미리보기

이 셀에서는 **문서 데이터셋**을 CSV 파일에서 읽어와 pandas **DataFrame**으로 로드합니다. `pd.read_csv("documents_meta.csv")`를 통해 CSV 파일을 읽고, 결과를 `documents_df`라는 DataFrame에 저장합니다. 데이터가 제대로 로드되었는지 확인하기 위해 `print(f"문서 수: {len(documents_df)}")`로 문서의 개수를 출력하고, `documents_df.head()`를 호출하여 데이터의 앞부분을 표시합니다. 이렇게 하면 데이터 프레임의 구조와 샘플 레코드를 확인할 수 있습니다.
**주요 내용:** 이 데이터에는 `doc_id` (문서 ID), `title` (제목), `content` (본문 내용), `author` (저자), `category` (카테고리) 등의 칼럼이 있습니다. 특히 `category` 칼럼에는 하나의 문서에 여러 카테고리가 세미콜론(`;`)으로 구분되어 들어 있을 수 있습니다 (예: `"문화;음악"`처럼 두 개의 카테고리). 이 정보를 나중에 벡터 DB에 메타데이터로 활용할 것입니다.

```python
import pandas as pd

# 다중 메타데이터가 포함된 CSV 파일 로딩
documents_df = pd.read_csv("documents_meta.csv")
print(f"문서 수: {len(documents_df)}")
documents_df.head()
```

**출력 설명:**

1. 첫 번째 출력은 **문서의 개수**입니다. `len(documents_df)` 결과를 출력한 것으로, 총 **30개의 문서**가 로드되었다는 뜻입니다.

```plaintext
문서 수: 30
```

2. 두 번째 출력은 **데이터프레임의 앞부분**을 표 형태로 보여줍니다. 각 열(Column)의 의미는 다음과 같습니다:

   * **doc\_id**: 문서를 식별하는 고유 ID (예: D1, D2, ...).
   * **title**: 문서 제목.
   * **content**: 문서의 본문 내용 (긴 텍스트이며 여기서는 일부만 보입니다).
   * **author**: 문서 저자 이름.
   * **category**: 문서의 카테고리 목록. (여러 개일 경우 세미콜론 `;`으로 구분되어 하나의 문자열로 표시됨)

아래 출력된 표는 상위 5개의 문서 레코드를 보여줍니다. 각 행마다 `doc_id`와 그에 대응하는 제목, 내용, 저자, 카테고리가 나열됩니다. 예를 들어, **D1** 문서는 제목이 "제주도 여행 가이드", 저자는 김민수, 카테고리는 "여행"으로 표시되어 있습니다. **D3** 문서를 보면 `category` 칼럼에 `"문화;음악"`으로 나타나 있는데, 이는 해당 문서가 두 가지 카테고리에 속함을 의미합니다 (문화와 음악). 내용 칼럼은 길이가 길기 때문에 일부만 보이며 `...`으로 생략된 부분도 있습니다.

```plaintext
  doc_id               title  \
0     D1          제주도 여행 가이드   
1     D2  전주 비빔밥과 진주 비빔밥 차이점   
2     D3         걸스데이 히트곡 분석   
3     D4          세종대왕과 훈민정음   
4     D5       이순신 장군의 명량 해전   

                                             content author category  
0  제주도는 대한민국의 대표 관광지로서, 한라산 등반, 성산 일출봉 관광, 해변 활동(...    김민수       여행   
1  비빔밥은 조선 시대부터 전해 내려온 대표적 한국 음식으로, 밥 위에 고명(채소·고기...    이영희       음식   
2  걸스데이는 2010년 데뷔한 대한민국의 4인조 걸그룹으로, 대표곡으로는 “Somet...    박지훈    문화;음악   
3  세종대왕(1397~1450)은 훈민정음을 창제하여 한글을 보급한 조선의 4대 임금입...    최수정    역사;교육   
4  이순신 장군(1545~1598)은 임진왜란 당시 명량 해전에서 13척의 배로 133...    정우성    역사;군사   
```

---

## 셀 4: Pinecone 벡터스토어 설정

이 셀에서는 **Pinecone** 서비스에 연결하고, 벡터 인덱스를 설정한 후 LangChain을 통해 **벡터 스토어** 객체를 초기화합니다. 주요 수행 작업은 다음과 같습니다:

* `Pinecone(api_key=...)`를 사용하여 Pinecone에 연결하는 **클라이언트 객체** `pc`를 생성합니다. (API 키는 앞서 환경 변수에서 불러온 값을 사용)
* `pc.list_indexes().names()`로 현재 Pinecone에 존재하는 인덱스 이름들을 가져와서, 우리의 인덱스 이름(`PINECONE_INDEX_NAME`)이 없으면 `pc.create_index(...)`로 새 인덱스를 만듭니다. 여기서 인덱스를 생성할 때 차원 수(`dimension`), 거리 계산 방식(`metric`), 지역 및 클라우드 설정(`ServerlessSpec`) 등을 환경 변수로 지정된 값들로 설정합니다. (예: 유클리디안 거리, 차원 1536 등)
* 인덱스가 이미 존재하거나 새로 생성되었다면, `pc.Index(PINECONE_INDEX_NAME)`로 해당 인덱스에 대한 핸들인 `index` 객체를 가져옵니다.
* OpenAI 임베딩 모델을 사용하기 위해 `OpenAIEmbeddings` 객체를 생성합니다. `model=OPENAI_EMBEDDING_MODEL`로 임베딩 모델 이름을 지정하고, OpenAI API 키를 전달하여 임베딩을 계산하는 엔진을 준비합니다.
* `PineconeVectorStore`를 초기화하여 LangChain이 사용할 **벡터스토어**를 만듭니다. 이때 인덱스 이름과 임베딩 모델을 연동하여, 나중에 문서를 추가하거나 검색할 수 있는 `vector_store` 객체가 생성됩니다.
* 마지막으로 `print("Pinecone 및 벡터 스토어 준비 완료")`로 모든 준비가 끝났음을 알립니다.

```python
from pinecone import Pinecone, ServerlessSpec
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore

# Pinecone 클라이언트 연결
pc = Pinecone(api_key=PINECONE_API_KEY)

# 인덱스가 없으면 생성
if PINECONE_INDEX_NAME not in pc.list_indexes().names():
    pc.create_index(
        name=PINECONE_INDEX_NAME,
        dimension=PINECONE_INDEX_DIMENSION,
        metric=PINECONE_INDEX_METRIC,
        spec=ServerlessSpec(region=PINECONE_INDEX_REGION, cloud=PINECONE_INDEX_CLOUD)
    )
index = pc.Index(PINECONE_INDEX_NAME)

# 임베딩 모델 생성
embedding_model = OpenAIEmbeddings(model=OPENAI_EMBEDDING_MODEL, openai_api_key=os.getenv("OPENAI_API_KEY"))
# Pinecone 벡터 스토어 설정
vector_store = PineconeVectorStore(index_name=PINECONE_INDEX_NAME, embedding=embedding_model)

print("Pinecone 및 벡터 스토어 준비 완료")
```

**출력 설명:** 이 셀의 실행 결과로 두 가지 출력이 나타났습니다. 첫째는 경고 메시지이고, 둘째는 준비 완료 메시지입니다:

* 첫 번째 **경고 메시지**는 Jupyter 환경에 **ipywidgets**가 설치되어 있지 않아 `tqdm` 진행 바를 사용할 수 없다는 내용입니다. 이는 환경 설정 관련 경고일 뿐, 코드 실행에는 큰 문제가 없습니다. (이 메시지는 주피터 노트북 상의 진행표시 UI와 관련된 것으로, 무시해도 됩니다.)

* 두 번째 줄 \*\*"Pinecone 및 벡터 스토어 준비 완료"\*\*는 우리가 작성한 출력으로, Pinecone에 정상적으로 연결되고 (필요시 인덱스를 생성하고) 벡터 스토어 객체까지 모두 준비되었음을 알려줍니다.

```plaintext
c:\Users\ssampooh\RAG-Retrieval\.conda\Lib\site-packages\tqdm\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
Pinecone 및 벡터 스토어 준비 완료
```

---

## 셀 5: Document 객체 생성 및 메타데이터 구성

이 셀에서는 앞서 불러온 DataFrame (`documents_df`)의 각 문서를 LangChain의 **Document 객체**로 변환하고, 여기에 **메타데이터**를 구성합니다. 단계별로 살펴보면 다음과 같습니다:

* `from langchain.schema import Document`를 통해 LangChain의 Document 클래스(구조)를 임포트합니다.
* `docs_to_upsert = []`로 빈 리스트를 생성하여, 변환된 Document 객체들을 담을 공간을 마련합니다.
* `for idx, row in documents_df.iterrows():`를 이용해 DataFrame의 각 행(row)을 하나씩 순회합니다. 각 `row`는 하나의 문서 데이터를 나타냅니다.

  * 각 문서의 `category` 필드는 문자열로 되어있는데, 예를 들어 `"역사;교육"`처럼 여러 카테고리가 하나의 문자열에 `;`로 연결돼 있습니다. 코드에서는 `row['category'].split(';')`를 사용하여 이러한 문자열을 `';'` 구분자로 분리하고, **리스트 형태** (`cats`)로 만듭니다. 이렇게 하면 `"역사;교육"` -> `['역사', '교육']`처럼 카테고리들을 개별 요소로 다룰 수 있습니다.
  * 분리한 `cats` 리스트와 함께, `doc_id`와 `author` 정보를 이용해 `metadata` 딕셔너리를 구성합니다. 결과적으로 각 문서에 대해 `metadata = {'doc_id': ..., 'author': ..., 'category': cats}` 형식의 메타데이터가 준비됩니다. (카테고리는 문자열이 아닌 **리스트**로 저장되는 점에 주목하세요. 나중에 필터링 검색 시 리스트 항목으로서 조회됩니다.)
  * `Document(page_content=row['content'], metadata=metadata)`를 호출하여 Document 객체를 생성합니다. `page_content`에는 문서의 본문 텍스트를 넣고, `metadata`에는 앞서 만든 메타데이터 딕셔너리를 첨부합니다. 그런 다음 이 Document 객체를 `docs_to_upsert` 리스트에 추가합니다. 이 과정을 모든 문서에 대해 반복하면, 각 문서가 LangChain의 Document로 변환되고 필요한 메타데이터가 포함됩니다.
* 루프가 끝나면, `print(f"업서트할 문서 수: {len(docs_to_upsert)}")`로 변환 완료된 문서 개수를 출력합니다. 여기서는 30개 문서 모두 변환되어 리스트에 담겼을 것이므로 "업서트할 문서 수: 30"이 출력됩니다. ("업서트"란 용어는 "업데이트 또는 삽입(upsert)"의 의미로, 곧 벡터DB에 이 문서들을 추가할 것이기 때문에 사용했습니다.)

```python
from langchain.schema import Document

# Document 리스트 생성
docs_to_upsert = []
for idx, row in documents_df.iterrows():
    # '역사;교육' → ['역사','교육'] 처럼 분리
    cats = row['category'].split(';')
    metadata = {
        'doc_id': row['doc_id'],
        'author': row['author'],
        'category': cats,   # 리스트로 넘기기
    }
    docs_to_upsert.append(Document(page_content=row['content'], metadata=metadata))
    
print(f"업서트할 문서 수: {len(docs_to_upsert)}")
```

**출력 설명:** `"업서트할 문서 수: 30"` 이 출력되며, 총 30개의 Document 객체가 생성되어 업서트 준비 리스트에 담겼음을 알려줍니다. 이 숫자는 앞서 CSV에서 불러온 문서 수와 일치하며, 변환 과정에서 누락되거나 오류 난 문서가 없음을 의미합니다.

```plaintext
업서트할 문서 수: 30
```

---

## 셀 6: Document 리스트 내용 확인

이 셀에서는 방금 생성한 `docs_to_upsert` 리스트를 그대로 출력하여 그 **내용을 확인**합니다. `docs_to_upsert`를 단순히 변수명으로 호출하면 Python의 리스트 내 모든 Document 객체들이 표시됩니다. 각 객체는 `Document(...)` 형태로 **메타데이터**와 \*\*내용(page\_content)\*\*를 담고 있기 때문에, 출력 결과를 통해 우리가 의도한 대로 정보가 들어갔는지 검증할 수 있습니다.

이 출력은 30개의 Document 객체를 리스트 형태(`[...]`)로 보여줍니다. 리스트의 **첫 번째 요소**는 `[` 바로 뒤에 표시되고, 이후 각 Document는 \*\*콤마(,)\*\*로 구분되어 줄바꿈되어 나타납니다. 각 Document 객체는 `Document(metadata={...}, page_content='...')` 형식으로, 메타데이터 딕셔너리와 본문 내용의 일부 (긴 텍스트 전체가 포함되지만 출력 시에는 그대로 표시됩니다) 가 포함되어 있습니다.

코드를 실행하면 Document들의 \_\_repr\_\_이 호출되어 다음과 같은 긴 리스트가 출력됩니다. 이를 통해 몇 가지를 확인할 수 있습니다:

* 각 Document의 `metadata`에 `doc_id`, `author`, `category`가 올바르게 들어갔는지 (예: D1 문서의 author는 김민수, category는 \['여행'] 형태의 리스트)
* `page_content`에 해당 문서의 본문이 잘 담겼는지 (본문 내용의 시작 부분이 보입니다)
* `category`가 문자열이 아니라 리스트로 표현되는지 (예: D3 문서의 category는 \['문화', '음악']처럼 대괄호로 묶인 리스트로 표시됨)

```python
docs_to_upsert
```

**출력 설명:** 아래는 `docs_to_upsert` 리스트의 내용을 나타낸 것입니다. 총 30개의 Document 객체가 대괄호 `[...]`로 감싸여 나열되어 있습니다. 각 줄은 하나의 Document를 나타내며, 객체 안에 `metadata`와 `page_content`가 표시됩니다:

* **metadata**: 우리가 구성한 메타데이터 딕셔너리로, `doc_id`, `author`, `category` 키를 가지고 있습니다. category는 리스트로 되어 있어 여러 값을 포함할 수 있습니다.
* **page\_content**: 실제 문서의 본문 텍스트입니다. 출력에는 긴 본문이 모두 표시되므로 일부는 중간에 생략된 듯한 `...`이 보일 수 있지만, 이는 본문 자체에 포함된 글자들입니다 (특히 일부 문서는 본문에 괄호나 `...` 등의 표시가 원래 있을 수 있습니다). 모든 본문이 원래 데이터대로 잘 들어가 있습니다.

예를 들어 첫 번째 Document를 보면 `doc_id: 'D1'`, `author: '김민수'`, `category: ['여행']`이며, `page_content`에 제주도 여행 가이드에 대한 내용이 문자열로 들어 있습니다. 각 문서별로 이러한 구조를 확인할 수 있고, 마지막 문서 D30까지 잘 포함되어 있는 것을 알 수 있습니다. 마지막 Document 출력이 `)]`로 끝나는 것은 리스트 `[`가 처음에 열렸기 때문에 마지막에 `]`으로 닫히면서 표시되는 것입니다 (콤마 없이 닫는 대괄호).

```plaintext
[Document(metadata={'doc_id': 'D1', 'author': '김민수', 'category': ['여행']}, page_content='제주도는 대한민국의 대표 관광지로서, 한라산 등반, 성산 일출봉 관광, 해변 활동(협재해수욕장·함덕해수욕장) 등이 인기입니다. 현지 음식으로는 흑돼지, 고기국수, 전복죽 등이 있으며, 카페 거리(서귀포시 대정읍 카페 거리)도 유명합니다. 교통은 렌터카나 시외버스를 주로 이용하며, 사전 예약 시 우도 투어나 올레길 트레킹도 즐길 수 있습니다.'),
 Document(metadata={'doc_id': 'D2', 'author': '이영희', 'category': ['음식']}, page_content='비빔밥은 조선 시대부터 전해 내려온 대표적 한국 음식으로, 밥 위에 고명(채소·고기·계란 등)을 올리고 고추장이나 간장을 섞어 먹습니다. 전주 비빔밥은 고명 종류가 다양하고 전주식 고추장을 쓰며, 잔치용으로도 유명합니다. 진주 비빔밥은 고기·회·나물 등을 섞어 더욱 풍부한 식감을 제공합니다. 두 지역 모두 역사적 배경과 재료 구성이 달라 맛과 풍미가 다릅니다.'),
 Document(metadata={'doc_id': 'D3', 'author': '박지훈', 'category': ['문화', '음악']}, page_content='걸스데이는 2010년 데뷔한 대한민국의 4인조 걸그룹으로, 대표곡으로는 “Something”, “Darling”, “Expectation” 등이 있습니다. 데뷔 초기 청순 컨셉에서 점차 섹시·여성미 컨셉으로 변화하며 음원 차트 상위권에 올랐습니다. 멤버 민아·유라·소진·혜리는 드라마·예능·광고 등 다양한 분야에도 진출해 활동 영역을 넓혔습니다.'),
 Document(metadata={'doc_id': 'D4', 'author': '최수정', 'category': ['역사', '교육']}, page_content='세종대왕(1397~1450)은 훈민정음을 창제하여 한글을 보급한 조선의 4대 임금입니다. 그가 훈민정음을 만든 배경에는 백성들의 문맹 문제 해결과 국가 통치 효율화가 있었습니다. 세종대왕의 업적은 한국 문화와 문자 체계에 지대한 영향을 미쳤으며, 훈민정음 해례본은 유네스코 세계기록유산으로 등재되었습니다.'),
 Document(metadata={'doc_id': 'D5', 'author': '정우성', 'category': ['역사', '군사']}, page_content='이순신 장군(1545~1598)은 임진왜란 당시 명량 해전에서 13척의 배로 133척의 왜선을 격파하면서 크게 승리했습니다. 전술적인 배 배치(학익진)와 기상·해류를 활용한 전략은 전투 역사에 길이 남을 전술입니다. 이순신의 업적은 한국 해군 전통과 군사 전략 연구에서 핵심 사례로 다뤄집니다.'),
 Document(metadata={'doc_id': 'D6', 'author': '한예슬', 'category': ['환경', '과학', '보고서']}, page_content='2024년 전 지구 평균 기온은 산업화 이전 대비 약 1.2℃ 상승했으며, 해수면 상승, 극지방 빙하 감소, 이상 기상 현상이 빈번해졌습니다. 탄소 배출량 감소를 위해 재생에너지 확대, 탄소 중립 정책, 전기차 보급 등이 전 세계 주요 과제로 떠올랐습니다. 특히 한국은 2050 탄소 중립 목표를 선포하고, 신재생에너지 비중 확대와 탄소세 도입을 논의 중에 있습니다.'),
 Document(metadata={'doc_id': 'D7', 'author': '강다니엘', 'category': ['기술', '윤리', 'AI']}, page_content='최근 인공지능 분야에서는 생성형 AI, 멀티모달 모델, 강화학습 기반 에이전트 개발이 활발합니다. GPT 계열(예: GPT-4, GPT-4o-mini)은 자연어 생성·이해 능력이 뛰어나며, DALL·E, Stable Diffusion은 이미지 생성, CLIP 등은 이미지·텍스트 융합 모델로 주목받고 있습니다. 또한 AI 윤리 이슈로는 데이터 편향, 프라이버시 침해, 자율성 문제 등이 논의되고 있습니다.'),
 Document(metadata={'doc_id': 'D8', 'author': '오정연', 'category': ['교통', '여행']}, page_content='서울 지하철은 1호선부터 9호선까지 운행되며, 주요 환승역으로는 서울역·강남역·종로3가역·고속터미널역 등이 있습니다. 기본 요금은 1,250원(성인 기준)이며, 거리에 따른 추가 요금이 부과됩니다. T-money 교통카드를 사용하면 자동으로 할인 적용이 됩니다. 출퇴근 시간대에는 혼잡하므로 가급적 비혼잡 시간대를 이용하고, 5호선 공덕역 환승 구간 등을 주의해야 합니다.'),
 Document(metadata={'doc_id': 'D9', 'author': '신동엽', 'category': ['문화', '음악', '역사']}, page_content='판소리는 소리꾼과 고수가 함께 공연하는 한국 전통 음악으로, 대표 작품에는 “춘향가”, “심청가”, “흥부가” 등이 있습니다. “춘향가”는 이몽룡과 성춘향의 사랑 이야기를 기반으로 하며, 욕망·권력·신분제 갈등이 서사에 녹아 있습니다. 판소리는 소리(창), 아니리, 발림(무용)으로 구성되며, 지역별 창법 차이를 보입니다.'),
 Document(metadata={'doc_id': 'D10', 'author': '윤아름', 'category': ['스포츠', '역사']}, page_content='한국 축구 대표팀은 2002 한일 월드컵 4강 진출, 2012 런던 올림픽 동메달 획득, 2022 카타르 월드컵 16강 진출 등의 성과를 이뤘습니다. 주요 선수로는 박지성·차범근·손흥민·기성용 등이 있으며, 감독으로는 거스 히딩크(2002)·슈틸리케(2022)가 있습니다. 최근에도 젊은 선수들의 활약으로 아시아 예선 및 월드컵 본선에서 경쟁력을 유지하고 있습니다.'),
 Document(metadata={'doc_id': 'D11', 'author': '김민수', 'category': ['건강', '생활']}, page_content='건강을 위해서는 규칙적 식습관, 적절한 운동(주 3회 이상, 유산소+근력), 충분한 수면(하루 7~8시간), 스트레스 관리(명상·취미활동), 정기 건강검진이 필요합니다. 특히 비만 예방을 위해 저탄수화물·고단백 식단, 주간 10,000보 걷기를 권장하며, 음주·흡연은 최소화해야 합니다. 또한 정신 건강을 위해 긍정적 마인드, 사회적 지지 체계 구축, 전문 상담 서비스 이용도 도움이 됩니다.'),
 Document(metadata={'doc_id': 'D12', 'author': '이영희', 'category': ['여행', '레저']}, page_content='서울 근교에서 당일치기로 다녀올 만한 여행지로는 가평 쁘띠프랑스, 남양주 수종사, 양평 두물머리, 용인 에버랜드 등이 있습니다. 기차·버스 노선이 잘 발달되어 있어 대중교통으로 이동이 편리하며, 차가 있다면 경춘고속도로를 이용해 접근성이 좋습니다. 사전 관광 예약 앱(예: 야놀자, 쿠팡트래블)에서도 할인 혜택을 확인할 수 있습니다.'),
 Document(metadata={'doc_id': 'D13', 'author': '박지훈', 'category': ['음식', '영양', '건강']}, page_content='비빔밥은 지역별로 칼로리, 탄수화물, 단백질, 지방 함량이 차이를 보입니다. 전주 비빔밥(약 650kcal)은 채소·고기·계란 비율이 고르지만, 진주 비빔밥(약 700kcal)은 해산물과 육류가 섞여 열량이 다소 높습니다. 안동 비빔밥은 재료가 비교적 간단해 600kcal 내외이며, 지역별 나물 종류와 기름 사용량이 칼로리 차이에 영향을 미칩니다.'),
 Document(metadata={'doc_id': 'D14', 'author': '최수정', 'category': ['기술', '환경', '과학']}, page_content='AI를 활용한 기후 예측 연구는 기계학습 모델을 통해 대규모 기상 데이터를 분석해 미래 기온·강수량을 예측합니다. 예를 들어, 한국 기상청과 KAIA가 공동으로 Deep Learning 기반 단기 기상 예보 모델을 개발했습니다. 강화학습을 적용해 극한 기상 상황 발생 확률을 시뮬레이션하는 연구도 진행 중이며, 기후 변화 대응 정책 수립에 활용되고 있습니다.'),
 Document(metadata={'doc_id': 'D15', 'author': '정우성', 'category': ['문화', '음악', '역사']}, page_content='가야금은 한국 전통 현악기로, 12개의 줄을 가진 칠현금(七絃琴) 계열 악기입니다. 역사적으로 가야 시대에 기원하며, 고려 말·조선 초기에 궁중 음악으로 발전했습니다. 현대에는 거문고·해금 등과 함께 국악 앙상블에서 주로 사용되며, 연주법은 손끝으로 줄을 튕기는 방식입니다.'),
 Document(metadata={'doc_id': 'D16', 'author': '한예슬', 'category': ['문화', '역사', '의식']}, page_content='전통 혼례는 예식 절차가 복잡하며, 폐백, 예단, 함, 폐백음식 등 여러 의례가 포함됩니다. 신랑 집 가마 행렬, 폐백상 차림, 결혼 예복(한복) 착용 방식 등이 있으며, 각 지역마다 의례 절차와 이름이 다를 수 있습니다. 최근에는 전통식을 모던하게 재해석한 혼례가 인기를 얻고 있습니다.'),
 Document(metadata={'doc_id': 'D17', 'author': '강다니엘', 'category': ['문화', '영화', '엔터테인먼트']}, page_content='2023년 한국 영화 흥행 순위 Top10에는 “헌트”, “비상선언”, “범죄도시3”, “마녀 Part2. The Other One”, “길복순”, “킹메이커”, “거룩한 밤: 데몬 헌트”, “외계+인 1부”, “외계+인 2부”, “밀수” 등이 랭크되었습니다. 장르별로는 액션·스릴러가 강세였으며, 감독·출연진 라인업이 흥행 성공에 큰 역할을 했습니다.'),
 Document(metadata={'doc_id': 'D18', 'author': '오정연', 'category': ['기술', '소프트웨어', '설치']}, page_content='윈도우즈 환경에서 한글이 깨지지 않고 시각화(그래프·차트)할 때는, 한글 폰트를 시스템에 설치한 뒤 matplotlib에 폰트 경로를 지정해야 합니다. 예를 들어, “NanumGothic” 또는 “Malgun Gothic” 폰트를 설치한 후, 파이썬 코드에 `plt.rc("font", family="Malgun Gothic")`를 추가합니다. 이 과정을 통해 차트 제목·축 레이블·범례 등에서 한글이 올바르게 출력됩니다.'),
 Document(metadata={'doc_id': 'D19', 'author': '신동엽', 'category': ['기술', '프로그래밍', '소프트웨어 개발']}, page_content='코드 악취(Bad Smell)는 설계·구현 단계에서 코드 구조가 비효율적이거나 유지보수에 어려움을 주는 패턴을 의미합니다. 대표적인 코드 악취 예시로는 중복 코드, 긴 메서드, 거대한 클래스, 불분명한 변수명 등이 있으며, 이를 해결하기 위해 리팩토링 기법(메서드 추출, 클래스 분할, 변수명 변경 등)을 적용합니다. 리팩토링은 코드 품질을 개선하고 버그 발생률을 줄이는 데 도움을 줍니다.'),
 Document(metadata={'doc_id': 'D20', 'author': '윤아름', 'category': ['기술', '프로그래밍', '테스팅']}, page_content='JUnit5는 모듈화된 구조(Java Platform Module System 지원), 확장 API, 더 유연한 애노테이션(`@Test`, `@BeforeEach` 등)과 더 강력한 어서션 기능을 제공하며, JUnit4와 비교해 테스트 라이프사이클 관리가 개선되었습니다. Eclipse에서 JUnit5 기반 테스트 클래스를 생성하려면, Maven/Gradle의 의존성을 설정한 뒤, `@Test` 애노테이션이 달린 메서드를 작성하면 됩니다. 반면 JUnit4는 `@RunWith`와 `@Rule`을 사용하며, 레거시 프로젝트 호환성이 높습니다.'),
 Document(metadata={'doc_id': 'D21', 'author': '김민수', 'category': ['게임', '엔터테인먼트', '기술']}, page_content='Wheel of Fortune은 랜덤으로 숫자·문자가 배치된 원판을 돌려 맞춰진 알파벳에 따라 점수를 획득하는 게임입니다. 플레이어는 자음·모음을 선택하며, 맞춘 글자 수만큼 상금을 얻고, 특정 스페셜 칸(“Bankrupt”, “Lose a Turn” 등)이 등장할 수 있습니다. 게임 로직에는 턴 기반 점수 시스템, 보너스 라운드, 시간 제한 요소가 포함되어 있으며, 알파벳 빈도에 따른 전략도 존재합니다.'),
 Document(metadata={'doc_id': 'D22', 'author': '이영희', 'category': ['기술', '프로그래밍', '소프트웨어 개발']}, page_content='싱글톤(Singleton) 패턴은 클래스의 인스턴스를 한 개만 생성하도록 보장하며, 전역 접근 지점을 제공하는 디자인 패턴입니다. Java 예제에서 `private static` 인스턴스 변수와 `getInstance()` 메서드를 사용해 단일 인스턴스를 반환합니다. 멀티스레드 환경에서는 `synchronized` 블록 또는 `volatile` 키워드를 활용해 안전을 보장해야 합니다.'),
 Document(metadata={'doc_id': 'D23', 'author': '박지훈', 'category': ['기술', '프로그래밍', '소프트웨어 개발']}, page_content='Strategy 패턴은 알고리즘 군을 캡슐화하여 상호 교환 가능하도록 만드는 패턴입니다. Java 예제에서는 인터페이스(예: PaymentStrategy)를 정의하고, `CreditCardStrategy`, `PayPalStrategy` 클래스로 구현합니다. 클라이언트는 런타임에 전략 객체를 주입해 유연한 알고리즘 선택이 가능합니다.'),
 Document(metadata={'doc_id': 'D24', 'author': '최수정', 'category': ['기술', '프로그래밍', '소프트웨어 개발']}, page_content='Command 패턴은 요청을 객체로 캡슐화하여 요청을 매개변수화하고, 호출자(invoker)와 수신자(receiver)를 분리합니다. Java 예제에서는 `Command` 인터페이스와 구체적 명령(`LightOnCommand`, `LightOffCommand`) 클래스를 만들고, `Invoker`가 명령 객체를 실행합니다. 이 패턴을 사용하면 요청 기록, 실행 취소(Undo), 큐잉 등이 용이합니다.'),
 Document(metadata={'doc_id': 'D25', 'author': '정우성', 'category': ['정책', '기술', '보고서']}, page_content='2025년 한국 정부는 “AI 국가전략 2.0”을 발표하며, 인공지능 기술 연구·개발(R&D) 예산을 3조 원으로 확대했습니다. 주요 정책으로는 AI 인재 양성, 규제 샌드박스 활성화, AI 윤리 가이드라인 강화, 공공데이터 개방 등이 포함됩니다. 특히 중소기업 대상 AI 솔루션 지원 사업이 증가하였고, 대학·연구기관 협력 프로젝트가 활발히 추진되고 있습니다.'),
 Document(metadata={'doc_id': 'D26', 'author': '한예슬', 'category': ['기술', '과학', '환경']}, page_content='딥러닝 모델(예: LSTM, Transformer 기반 시계열 모델)을 활용한 기상 예측은 과거 기상 데이터로부터 패턴을 학습해 미래 기온·강수량을 예측합니다. 한국 기상청의 Deep Learning 기반 장기 예측 시스템은 50년 치 데이터를 학습해 태풍 경로 예측 정확도를 10% 향상시켰습니다. 또한, 강화학습 기법을 적용한 극한 기상 시뮬레이션 사례도 연구 중입니다.'),
 Document(metadata={'doc_id': 'D27', 'author': '강다니엘', 'category': ['기술', '데이터베이스', '비교']}, page_content='ChromaDB와 Qdrant는 벡터 검색 라이브러리로, ChromaDB는 오픈소스 벡터 DB로 간단한 파이썬 인터페이스를 제공하며, Qdrant는 Rust 기반 고성능 벡터 DB로 GPU 가속 지원 및 필터링 기능이 강점입니다. 성능 비교 실험 시 인덱싱 속도, 검색 응답 속도, 메모리 사용량, 스케일링 용이성 등을 비교합니다. 파이썬 코드 예제와 벤치마크 결과가 공개되어 있어, 개발자가 선택하기 용이합니다.'),
 Document(metadata={'doc_id': 'D28', 'author': '오정연', 'category': ['기술', 'AI', '검색']}, page_content='Contextual Compression은 긴 텍스트에서 핵심 정보만 추출해 압축(요약)한 뒤 검색 효율을 높이는 기법입니다. 예를 들어, 긴 문서를 PEGASUS 기반 한국어 요약 모델로 요약한 뒤, 압축된 요약문을 임베딩해 검색하면 문서 길이가 길어도 핵심 검색 품질을 유지할 수 있습니다. 압축 전후 검색 성능 차이를 평가할 때 Precision@k, Recall@k, nDCG@k 지표를 사용합니다.'),
 Document(metadata={'doc_id': 'D29', 'author': '신동엽', 'category': ['기술', 'AI', '검색']}, page_content='Self-Query Retriever는 문서 메타데이터(제목·요약·키워드)를 분석해, 사용자가 실제로 검색할 만한 쿼리를 GPT-4o-mini 등 생성형 모델로 생성한 뒤, 생성된 가상 쿼리를 다시 검색에 활용하는 기법입니다. 이 과정을 통해 사용자가 입력한 실제 질의보다 검색 품질을 높이는 효과를 얻을 수 있으며, 생성된 쿼리는 ‘Self-Query’라고 불립니다.'),
 Document(metadata={'doc_id': 'D30', 'author': '윤아름', 'category': ['기술', 'AI', '검색']}, page_content='Multi-Hop Retrieval은 한 단계의 검색으로 해결되지 않는 복합 질문에 대응하기 위해, 여러 단계(홉)로 나눠서 검색을 수행하는 기법입니다. 예를 들어, “세종대왕이 훈민정음을 만든 이유를 바탕으로 AI 윤리 가이드라인 사례를 찾고 싶다”는 질문에서, 1단계로 ‘세종대왕 훈민정음 배경’(→D4 자료), 2단계로 ‘AI 윤리 가이드라인 사례’(→D7 또는 D25)로 연결해 답을 도출합니다. 단계별 결과를 종합해 최종 순위를 매깁니다.')]
```

---

## 셀 7: Pinecone에 문서 업서트 (추가)

이 셀에서는 준비된 문서들을 실제로 Pinecone 벡터 스토어에 **업서트(upsert)** 합니다. 업서트란 이미 존재하면 업데이트하고 없으면 새로 삽입하는 연산으로, 여기서는 문서 전체를 **추가**한다고 이해하면 됩니다. 코드 동작은 다음과 같습니다:

* `vector_store.add_documents(docs_to_upsert)`를 호출하여, 앞서 만든 Document 객체 리스트를 Pinecone 벡터스토어에 추가합니다. 내부적으로 이 함수는 각 문서의 `page_content`를 임베딩(숫자 벡터)으로 변환하고, 해당 벡터와 메타데이터를 Pinecone 인덱스에 저장합니다. 즉, **30개 문서가 Pinecone에 인덱싱**되는 것입니다.
* 문서 저장이 완료되면 `print("문서 업서트 완료 — Pinecone 인덱스에 저장됨")`으로 작업 완료를 출력합니다.

코드를 실행하면 Pinecone에 접속하여 데이터를 저장하는 과정이 일어나며, 완료 후에는 준비된 메시지만 출력됩니다.

```python
# 벡터 스토어에 다중 메타데이터 문서 업서트
vector_store.add_documents(docs_to_upsert)
print("문서 업서트 완료 — Pinecone 인덱스에 저장됨")
```

**출력 설명:** Pinecone에 모든 문서가 잘 저장되었다면 아래와 같은 확인 메시지가 출력됩니다. 만약 에러가 발생했다면 이 메시지 대신 예외가 발생했겠지만, 출력이 정상적으로 보이는 것으로 보아 성공적으로 30개 문서가 인덱스에 올라간 것을 의미합니다.

```plaintext
문서 업서트 완료 — Pinecone 인덱스에 저장됨
```

---

## 셀 8: 메타데이터 필터를 사용한 벡터 검색

마지막으로 이 셀에서는 **메타데이터 필터링 검색**을 수행합니다. 사용자가 입력한 질의(query)에 대해서 Pinecone 벡터스토어에서 유사한 문서를 검색하되, 특정 메타데이터 조건을 만족하는 결과만 얻도록 하는 예시입니다. 주요 흐름은 다음과 같습니다:

* `query = "훈민정음"`: 검색에 사용할 쿼리를 정의합니다. 여기서는 \*\*"훈민정음"\*\*이라는 키워드로 문서를 찾아볼 것입니다.
* `vector_store.similarity_search(query, k=5, filter={'category': {'$in': ['역사']}})`를 호출하여, 쿼리에 대한 **코사인 유사도 기반 상위 5개 문서**를 검색합니다. `filter` 파라미터는 메타데이터 조건을 지정하는 부분으로, 여기서는 `{'category': {'$in': ['역사']}}`라고 되어 있습니다. 이 조건은 *category 메타데이터 필드에 '역사'가 포함되어 있는 문서들만 검색 대상에 포함*하라는 뜻입니다. (즉, 카테고리 리스트 중 '역사'를 갖고 있는 문서만 후보로 삼아 유사도 상위 5개를 반환)
* 검색 결과인 `results`는 Document 객체들의 리스트입니다. `print("필터링된 검색 결과 (category='역사') — 상위 5개 문서 ID:")`로 헤더를 출력한 후, `for doc in results:` 루프를 돌면서 각 결과 문서의 ID와 카테고리를 출력합니다. `doc.metadata['doc_id']`로 문서 ID, `doc.metadata['category']`로 그 문서의 카테고리 리스트를 가져와 표시합니다.
* 결국, 주어진 쿼리에 대해 **카테고리가 '역사'인 문서들 중 상위 5개**를 찾아 그 ID와 카테고리를 보여주는 것이 목적입니다.

```python
from langchain.schema import Document

# 메타데이터 필터 예시: category에 '역사'가 포함된 문서만 검색
query = "훈민정음"
results = vector_store.similarity_search(
    query,
    k=5,
    filter={'category': {'$in': ['역사']}}
)
print("필터링된 검색 결과 (category='역사') — 상위 5개 문서 ID:")
for doc in results:
    print(doc.metadata['doc_id'], doc.metadata['category'])
```

**출력 설명:** 검색된 문서들의 ID와 카테고리 목록이 5줄 나옵니다. 맨 윗줄은 안내 문구이고, 그 아래 5개의 결과가 나열되었습니다:

* 출력 첫 줄은 **필터 조건과 결과 설명**으로, `(category='역사')`로 필터링된 상위 5개 문서의 ID를 보여준다고 명시합니다.
* 이후 각 줄은 하나의 검색 결과를 나타내며, **문서 ID**와 해당 문서의 **카테고리 리스트**를 보여줍니다. 예를 들어 첫 번째 결과 `D4 ['역사', '교육']`는 문서 D4가 검색되었고 그 카테고리가 \['역사', '교육']임을 뜻합니다. 모든 결과의 카테고리 리스트를 보면 반드시 '역사'가 포함되어 있다는 것을 확인할 수 있습니다. 이는 필터 조건을 만족함과 동시에 쿼리 "훈민정음"과도 연관성이 높은 문서들이 선택된 것입니다.
* 결과들은 유사도 순으로 정렬되어 있으므로, 첫 번째 문서(D4)가 쿼리와 가장 관련성이 높았고, 다섯 번째 문서(D5)가 그 다음으로 관련성이 있는 것으로 볼 수 있습니다. 특히 **D4** 문서는 "세종대왕과 훈민정음"이라는 제목(역사 관련)으로 훈민정음과 직접 연관이 있어 최상위로 나온 것으로 추측됩니다.

```plaintext
필터링된 검색 결과 (category='역사') — 상위 5개 문서 ID:
D4 ['역사', '교육']
D15 ['문화', '음악', '역사']
D9 ['문화', '음악', '역사']
D10 ['스포츠', '역사']
D5 ['역사', '군사']
```

각 결과의 `doc_id`를 보면 D4, D15, D9, D10, D5 순이며, 이들 문서는 모두 `category`에 '역사'를 포함하고 있습니다. 이렇게 LangChain과 Pinecone을 활용하여 **메타데이터 필터링된 벡터 검색**을 수행한 예제를 마무리했습니다.
