{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161c1eb8",
   "metadata": {},
   "source": [
    "### from : 03.rrf_comparision.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b25650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환경 변수 로딩 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 가져오기\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_LLM_MODEL = os.getenv(\"OPENAI_LLM_MODEL\")\n",
    "OPENAI_EMBEDDING_MODEL = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_REGION = os.getenv(\"PINECONE_INDEX_REGION\")\n",
    "PINECONE_INDEX_CLOUD = os.getenv(\"PINECONE_INDEX_CLOUD\")\n",
    "PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_INDEX_METRIC = os.getenv(\"PINECONE_INDEX_METRIC\")\n",
    "PINECONE_INDEX_DIMENSION = int(os.getenv(\"PINECONE_INDEX_DIMENSION\"))\n",
    "\n",
    "print(\"환경 변수 로딩 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3330509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 30\n",
      "질의 수: 30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 문서 및 질의 데이터 로드\n",
    "documents_df = pd.read_csv(\"../../datas/documents.csv\")\n",
    "queries_df = pd.read_csv(\"../../datas/queries.csv\")\n",
    "\n",
    "print(f\"문서 수: {len(documents_df)}\")\n",
    "print(f\"질의 수: {len(queries_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51d5b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mecab 기반 BM25 검색: ['D1', 'D12', 'D2', 'D3', 'D4']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# 예시: Mecab 형태소 분석기로 문서 토큰화\n",
    "mecab = Okt()\n",
    "\n",
    "tokenized_docs = [mecab.morphs(content) for content in documents_df['content']]\n",
    "bm25 = BM25Okapi(tokenized_docs)\n",
    "\n",
    "def bm25_search(query, top_k=5):\n",
    "    query_tokens = mecab.morphs(query)\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    ranked_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    return [documents_df['doc_id'].iloc[i] for i in ranked_idx[:top_k]]\n",
    "\n",
    "print(\"Mecab 기반 BM25 검색:\", bm25_search(\"제주도 관광 명소\", top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c14bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 'ir' 인덱스에 연결하여 Dense Retrieval 설정 완료\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index = pc.Index(PINECONE_INDEX_NAME)  \n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=OPENAI_EMBEDDING_MODEL,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "vector_store = PineconeVectorStore(\n",
    "    index_name=PINECONE_INDEX_NAME,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "print(\"기존 'ir' 인덱스에 연결하여 Dense Retrieval 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac02f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def parse_relevant(relevant_str):\n",
    "    pairs = relevant_str.split(';')\n",
    "    rel_dict = {}\n",
    "    for pair in pairs:\n",
    "        doc_id, grade = pair.split('=')\n",
    "        rel_dict[doc_id] = int(grade)\n",
    "    return rel_dict\n",
    "\n",
    "def compute_metrics(predicted, relevant_dict, k=5):\n",
    "    hits = sum(1 for doc in predicted[:k] if doc in relevant_dict)\n",
    "    precision = hits / k\n",
    "    total_relevant = len(relevant_dict)\n",
    "    recall = hits / total_relevant if total_relevant > 0 else 0\n",
    "    rr = 0\n",
    "    for idx, doc in enumerate(predicted):\n",
    "        if doc in relevant_dict:\n",
    "            rr = 1 / (idx + 1)\n",
    "            break\n",
    "    num_correct = 0\n",
    "    precisions = []\n",
    "    for i, doc in enumerate(predicted[:k]):\n",
    "        if doc in relevant_dict:\n",
    "            num_correct += 1\n",
    "            precisions.append(num_correct / (i + 1))\n",
    "    ap = np.mean(precisions) if precisions else 0\n",
    "    return precision, recall, rr, ap\n",
    "\n",
    "def evaluate_all(method_results, queries_df, k=5):\n",
    "    prec_list, rec_list, rr_list, ap_list = [], [], [], []\n",
    "    for idx, row in queries_df.iterrows():\n",
    "        qid = row['query_id']\n",
    "        relevant_dict = parse_relevant(row['relevant_doc_ids'])\n",
    "        predicted = method_results[qid]\n",
    "        p, r, rr, ap = compute_metrics(predicted, relevant_dict, k)\n",
    "        prec_list.append(p)\n",
    "        rec_list.append(r)\n",
    "        rr_list.append(rr)\n",
    "        ap_list.append(ap)\n",
    "    return {\n",
    "        'P@5': np.mean(prec_list),\n",
    "        'R@5': np.mean(rec_list),\n",
    "        'MRR': np.mean(rr_list),\n",
    "        'MAP': np.mean(ap_list)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc7d2e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRF 결합 완료 (상위 5개 저장됨)\n",
      "질의 Q1 RRF 상위 5: ['D1', 'D2', 'D12', 'D8', 'D17']\n"
     ]
    }
   ],
   "source": [
    "# RRF 결합 함수\n",
    "def rrf_rank(bm25_list, dense_list, k=60):\n",
    "    # bm25_list, dense_list: 상위 20개 문서 ID 리스트\n",
    "    candidate_scores = {}\n",
    "    for rank, doc in enumerate(bm25_list):\n",
    "        candidate_scores[doc] = candidate_scores.get(doc, 0) + 1 / (rank + 1 + k)\n",
    "    for rank, doc in enumerate(dense_list):\n",
    "        candidate_scores[doc] = candidate_scores.get(doc, 0) + 1 / (rank + 1 + k)\n",
    "    # 점수 정렬\n",
    "    ranked = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in ranked]\n",
    "\n",
    "# BM25 상위 20, Dense 상위 20, RRF 상위 5 결과 생성\n",
    "bm25_candidates = {}\n",
    "dense_candidates = {}\n",
    "rrf_results = {}\n",
    "for idx, row in queries_df.iterrows():\n",
    "    qid = row['query_id']\n",
    "    query_text = row['query_text']\n",
    "    bm25_top20 = bm25_search(query_text, top_k=20)\n",
    "    dense_top20 = [doc.metadata['doc_id'] for doc in vector_store.similarity_search(query_text, k=20)]\n",
    "    bm25_candidates[qid] = bm25_top20\n",
    "    dense_candidates[qid] = dense_top20\n",
    "    rrf_list = rrf_rank(bm25_top20, dense_top20, k=60)\n",
    "    rrf_results[qid] = rrf_list[:5]\n",
    "\n",
    "print(\"RRF 결합 완료 (상위 5개 저장됨)\")\n",
    "# 예시 확인\n",
    "print(\"질의 Q1 RRF 상위 5:\", rrf_results[queries_df.loc[0, 'query_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae90443e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>BM25</th>\n",
       "      <th>Dense</th>\n",
       "      <th>RRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P@5</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R@5</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>1.716667</td>\n",
       "      <td>0.927778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MRR</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAP</td>\n",
       "      <td>0.957407</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.955185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric      BM25     Dense       RRF\n",
       "0    P@5  0.253333  0.466667  0.266667\n",
       "1    R@5  0.894444  1.716667  0.927778\n",
       "2    MRR  0.966667  0.977778  0.983333\n",
       "3    MAP  0.957407  0.978148  0.955185"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# BM25 상위 5 리스트 생성\n",
    "bm25_results_5 = {qid: lst[:5] for qid, lst in bm25_candidates.items()}\n",
    "# Dense 상위 5 리스트 생성\n",
    "dense_results_5 = {qid: lst[:5] for qid, lst in dense_candidates.items()}\n",
    "\n",
    "# 평가\n",
    "bm25_metrics = evaluate_all(bm25_results_5, queries_df, k=5)\n",
    "dense_metrics = evaluate_all(dense_results_5, queries_df, k=5)\n",
    "rrf_metrics = evaluate_all(rrf_results, queries_df, k=5)\n",
    "\n",
    "# 결과 테이블\n",
    "df_metrics = pd.DataFrame({\n",
    "    'Metric': ['P@5', 'R@5', 'MRR', 'MAP'],\n",
    "    'BM25': [bm25_metrics['P@5'], bm25_metrics['R@5'], bm25_metrics['MRR'], bm25_metrics['MAP']],\n",
    "    'Dense': [dense_metrics['P@5'], dense_metrics['R@5'], dense_metrics['MRR'], dense_metrics['MAP']],\n",
    "    'RRF': [rrf_metrics['P@5'], rrf_metrics['R@5'], rrf_metrics['MRR'], rrf_metrics['MAP']]\n",
    "})\n",
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
